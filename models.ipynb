{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a3d519f",
   "metadata": {},
   "source": [
    "Link to dataset: https://archive.ics.uci.edu/ml/datasets/SGEMM+GPU+kernel+performance#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afba972",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17cc2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b89ff",
   "metadata": {},
   "source": [
    "Load dataset into Spark dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd413c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"sgemm_product.csv\", header=\"true\", inferSchema=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb99c5",
   "metadata": {},
   "source": [
    "Examine first 10 rows of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889129c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-----+-----+-----+-----+---+---+---+----+----+---+---+---------+---------+---------+---------+\n",
      "|MWG|NWG|KWG|MDIMC|NDIMC|MDIMA|NDIMB|KWI|VWM|VWN|STRM|STRN| SA| SB|Run1 (ms)|Run2 (ms)|Run3 (ms)|Run4 (ms)|\n",
      "+---+---+---+-----+-----+-----+-----+---+---+---+----+----+---+---+---------+---------+---------+---------+\n",
      "| 16| 16| 16|    8|    8|    8|    8|  2|  1|  1|   0|   0|  0|  0|   115.26|   115.87|   118.55|    115.8|\n",
      "| 16| 16| 16|    8|    8|    8|    8|  2|  1|  1|   0|   0|  0|  1|    78.13|    78.25|    79.25|    79.19|\n",
      "| 16| 16| 16|    8|    8|    8|    8|  2|  1|  1|   0|   0|  1|  0|    79.84|    80.69|    80.76|    80.97|\n",
      "| 16| 16| 16|    8|    8|    8|    8|  2|  1|  1|   0|   0|  1|  1|    84.32|     89.9|    86.75|    85.58|\n",
      "| 16| 16| 16|    8|    8|    8|    8|  2|  1|  1|   0|   1|  0|  0|   115.13|   121.98|   122.73|   114.81|\n",
      "| 16| 16| 16|    8|    8|    8|    8|  2|  1|  1|   0|   1|  0|  1|     81.1|    82.41|    87.01|    82.14|\n",
      "| 16| 16| 16|    8|    8|    8|    8|  2|  1|  1|   0|   1|  1|  0|    83.31|    82.86|     88.6|    82.97|\n",
      "| 16| 16| 16|    8|    8|    8|    8|  2|  1|  1|   0|   1|  1|  1|    93.13|     94.3|    96.19|    94.43|\n",
      "| 16| 16| 16|    8|    8|    8|    8|  2|  1|  1|   1|   0|  0|  0|   117.38|   116.95|   124.15|   117.83|\n",
      "| 16| 16| 16|    8|    8|    8|    8|  2|  1|  1|   1|   0|  0|  1|    85.76|     85.3|    86.96|    87.19|\n",
      "+---+---+---+-----+-----+-----+-----+---+---+---+----+----+---+---+---------+---------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ca217",
   "metadata": {},
   "source": [
    "We see some integer and a few binary variables. Let us pick any one Run variable as our target variable, say Run1. So drop the Run 2, 3, 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87dda605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Run2 (ms)\", \"Run3 (ms)\", \"Run4 (ms)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97559d6b",
   "metadata": {},
   "source": [
    "Check schema and data types of variables. Convert all variables to double if they are not already so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14064d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MWG: integer (nullable = true)\n",
      " |-- NWG: integer (nullable = true)\n",
      " |-- KWG: integer (nullable = true)\n",
      " |-- MDIMC: integer (nullable = true)\n",
      " |-- NDIMC: integer (nullable = true)\n",
      " |-- MDIMA: integer (nullable = true)\n",
      " |-- NDIMB: integer (nullable = true)\n",
      " |-- KWI: integer (nullable = true)\n",
      " |-- VWM: integer (nullable = true)\n",
      " |-- VWN: integer (nullable = true)\n",
      " |-- STRM: integer (nullable = true)\n",
      " |-- STRN: integer (nullable = true)\n",
      " |-- SA: integer (nullable = true)\n",
      " |-- SB: integer (nullable = true)\n",
      " |-- Run1 (ms): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96207b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df = df.select([col(c).cast(\"double\") for c in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc73a34",
   "metadata": {},
   "source": [
    "Now, apply gradient boosting regression model to the dataset since our target variable is continuous. Train and test the model and get the error rates for them.\n",
    "Sources cited: \n",
    "https://docs.databricks.com/_extras/notebooks/source/gbt-regression.html  https://www.datatechnotes.com/2021/05/mllib-gradient-boosted-tree-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca6f6939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  127.43825270739755\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    " \n",
    "# Remove the target column from the input feature set.\n",
    "features = df.columns\n",
    "features.remove('Run1 (ms)')\n",
    "\n",
    "#We need to pack all the predictor columns into one for PySpark.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "\n",
    "va_df = vectorAssembler.transform(df)\n",
    "\n",
    "#Split data into test and train: 80-20\n",
    "train, test = va_df.randomSplit([0.8, 0.2], seed = 0)\n",
    "\n",
    "#Set up gradient booster\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(featuresCol='features', labelCol=\"Run1 (ms)\", maxIter=10)\n",
    "gbt = gbt.fit(train)\n",
    "\n",
    "mdata = gbt.transform(test)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "rmse=RegressionEvaluator(labelCol=\"Run1 (ms)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse=rmse.evaluate(mdata) \n",
    " \n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b585e",
   "metadata": {},
   "source": [
    "Conclusion: We got low RMSE for our model, although more could have been done to clean and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0de5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
